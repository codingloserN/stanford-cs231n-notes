# Lecture 2:图像分类

## 1.机器学习的过程中在做什么？

通过标注好的图片集(image&label)来得到一个模型。

```python
def train(images,labels):
 # Machine learning!
 return model	
```

通过得到的模型，往其中输入图片集来得到一个机器给你标注的标签。

```python
def predict(model,test_images):
#Use model to predict labels
return test_labels
```

![image-20230711114642183](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230711114642183.png)

## 2.初步探索——最邻近分类器(nearest neighbor classifier)

对于一张图片来说，我们看到的是这个图片上显示的各个物体的对象，而对于一台机器来说，它看到的就是一个巨大的矩阵。那么对于图像的识别，也就是矩阵的识别，人类开始尝试让机器通过某种算法来能够识别出“图像”的含义。

（nearest neighbor classifier）算法就在这时出现了，它的原理很简单：对于两个图片来说（在机器视角就是两个矩阵），当像下面这样，每个点的综合差值差的最小时他俩长得越像。

![矩阵的l1距离](http://cs231n.github.io/assets/nneg.jpeg)



### 那么思路就出来了：

1. 人工手动标注出一组图片数据集来，那么对于这个数据集来说每一张图片意味着什么都有人工给他打上的标签。

2. 让机器把目标图片与所有的图片进行对比，把目标图片的类别归到长得最像的图像中，即如果图片A与B的差值d(A,B)是与数据集中所有图片比较得到的最小值，那么证明A与B最相似。即label(A)=label(B)(已知)。

3. 在确定两个图片长得像的这件事上，有很多种计算算法，就像计算平均数时有什么加权平均值、算数平均值、平方根平均值之类的东西。

4. 然后又有人再次之上提出了进一步的想法，和目标图片长得最像的那一个图片(neighbor)并不一定和它时同一个类别，但是和他长得很像的一堆图片里面少数服从多数，最多的那些图片与目标图片是同一个类别的可能性最大。——这就是K邻近分类器。

   ![img](https://pic3.zhimg.com/80/v2-c3f1d2553e7467d7da5f9cd538d2b49a_720w.webp)

5. 测试的时候常常采用k-fold cross-validation(k份交叉数据验证)

​			k=5:

![k-fold 交叉验证](http://cs231n.github.io/assets/crossval.jpeg)

意思其实就是把原始数据分成k份，轮流使用其中k-1份作为训练数据，而剩余的1份作为交叉验证数据(因此其实对于k-fold cross-validation我们会得到k个accuracy)。

### 缺点：

![image-20230711141324327](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230711141324327.png)

1.它仅仅依靠像素点来判断类别真的是太原始了，将原图像的像素点做一点点的改动就会造成算法的计算结果产生大幅度的差异。

而且以cxk打篮球为例，长得像的图片和他俩类别是一样的还是差的挺多的。

2.这种图像识别的方法训练时的复杂度是O(1)——即把目标图片矩阵加载进来。而在predict的时候的算法复杂度为O(n)——需要逐个与数据集上的图片进行对比。这个太不符合我们的实际开发运用模式了，一般来说，我们希望训练的时候我们提供大规模的运算单元集群来训练出一个比较好的模型，而在最终对数据的预测上我们消耗较少的算力就可以完成这件事情。KNN所作的事情恰恰相反。

## 3.更进一步：线性分类

![image-20230711145113775](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230711145113775.png)

我们拿这只猫咪的图片来说明线性拟合算法是个什么东西：

我们有一个函数f(x，y)来充当这个算法，而对于这个转换函数我们有两个参数：x与W。

`x`是这个图片，以上图举例来看，假设这张图片的分辨率为32x32，是一张`RGB`3通道的图片，那么对于这个图片来说，他是由32x32x3给数据构成的。

`W`则代表一组参数，通常是一个矩阵。它具体的确定会与这个函数f(x,y)最终输出有关，请往下看，在5分钟内，你将能知道所有的这一切是什么，但是容我再铺垫一下以更好的解释它。

对于上述这个例子来说，我们使用的数据集`CIFAR10`有50000张，它们都是属于10个类别的。所以**我们最后的输出是**得到10个数字，这些数字的数值代表该图片属于某个类别的概率有多大。(可以将它们看作例如10分满分制机器的打分)

在介绍完这个概念以后，我们对参数的格式(为什么是一个10*3072的矩阵而不是别的！)就可以做出解释了

![image-20230711150311556](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230711150311556.png)

说回到对参数的解释上面：

`x`是这个图片，以上图举例来看，假设这张图片的分辨率为32x32，是一张`RGB`3通道的图片，那么对于这个图片来说，他是由32x32x3给数据构成的。

`W`则代表一组参数，通常是一个矩阵。之所以它是10x3072的矩阵，是因为`1`:`x`是3072x1的矩阵(32x32x3),`2`:输出得是一个10x1的矩阵`3`我们规定了`f(x,W)的函数体为Wx(相乘)`。所以这三者决定了`W`必须是一个10x3072的矩阵。

![image-20230711150812853](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230711150812853.png)

有时还会有偏差矩阵(`b`：bias),也要在矩阵运算后满足我们输出的格式。

**这是一个抽象出来的简单的实例**：根据上面所提供的方法就可以知道每一个参数的形式还有参数的值的意义

![image-20230711150934647](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20230711150934647.png)

